{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8083d414",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-04T09:39:33.570212Z",
     "iopub.status.busy": "2024-07-04T09:39:33.569782Z",
     "iopub.status.idle": "2024-07-04T09:39:34.447143Z",
     "shell.execute_reply": "2024-07-04T09:39:34.446113Z"
    },
    "papermill": {
     "duration": 0.887739,
     "end_time": "2024-07-04T09:39:34.450020",
     "exception": false,
     "start_time": "2024-07-04T09:39:33.562281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c523c0",
   "metadata": {
    "papermill": {
     "duration": 0.004993,
     "end_time": "2024-07-04T09:39:34.460859",
     "exception": false,
     "start_time": "2024-07-04T09:39:34.455866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> **Tokenization; Stop Word; Stemming; Lemitization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d08439d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:39:34.473733Z",
     "iopub.status.busy": "2024-07-04T09:39:34.473196Z",
     "iopub.status.idle": "2024-07-04T09:39:36.739463Z",
     "shell.execute_reply": "2024-07-04T09:39:36.737819Z"
    },
    "papermill": {
     "duration": 2.276461,
     "end_time": "2024-07-04T09:39:36.742720",
     "exception": false,
     "start_time": "2024-07-04T09:39:34.466259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "\n",
      "The sentence input used is : \n",
      "\n",
      " He stepped gingerly onto the bridge knowing, that enchantment awaited on the other side.\n",
      "It was difficult for Mary to admit; that most of her workout consisted of exercising poor judgment.\n",
      "\n",
      "\n",
      "The tokenized words are \n",
      " ['He', 'stepped', 'gingerly', 'onto', 'the', 'bridge', 'knowing', ',', 'that', 'enchantment', 'awaited', 'on', 'the', 'other', 'side', '.', 'It', 'was', 'difficult', 'for', 'Mary', 'to', 'admit', ';', 'that', 'most', 'of', 'her', 'workout', 'consisted', 'of', 'exercising', 'poor', 'judgment', '.']\n"
     ]
    }
   ],
   "source": [
    "#1} Tokenization : Tokens are formed\n",
    "import nltk\n",
    "nltk.download(\"punkt\")#punkt sentence tokenizer tokenizes the sentence and works on unsupervised learning and can be trained on unlabled data.\n",
    "#   Word tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"He stepped gingerly onto the bridge knowing, that enchantment awaited on the other side.\\nIt was difficult for Mary to admit; that most of her workout consisted of exercising poor judgment.\"\n",
    "tokens = word_tokenize(text)\n",
    "print(\"\\nThe sentence input used is : \\n\\n\",text)\n",
    "print(\"\\n\\nThe tokenized words are \\n\",tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f4e9b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:39:36.759804Z",
     "iopub.status.busy": "2024-07-04T09:39:36.758442Z",
     "iopub.status.idle": "2024-07-04T09:39:36.765667Z",
     "shell.execute_reply": "2024-07-04T09:39:36.764505Z"
    },
    "papermill": {
     "duration": 0.019971,
     "end_time": "2024-07-04T09:39:36.769556",
     "exception": false,
     "start_time": "2024-07-04T09:39:36.749585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The tokenized sentence are: \n",
      " ['He stepped gingerly onto the bridge knowing, that enchantment awaited on the other side.', 'It was difficult for Mary to admit; that most of her workout consisted of exercising poor judgment.']\n"
     ]
    }
   ],
   "source": [
    "#   Sentence tokenizer\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "tokens_sent = sent_tokenize(text)\n",
    "print(\"\\nThe tokenized sentence are: \\n\",tokens_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d76363f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:39:36.782583Z",
     "iopub.status.busy": "2024-07-04T09:39:36.782185Z",
     "iopub.status.idle": "2024-07-04T09:39:36.793485Z",
     "shell.execute_reply": "2024-07-04T09:39:36.792179Z"
    },
    "papermill": {
     "duration": 0.020505,
     "end_time": "2024-07-04T09:39:36.795786",
     "exception": false,
     "start_time": "2024-07-04T09:39:36.775281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The stop words are removed now, Tokenized words or filtered tokenized words are : \n",
      "\n",
      " ['He', 'stepped', 'gingerly', 'onto', 'bridge', 'knowing', ',', 'enchantment', 'awaited', 'side', '.', 'It', 'difficult', 'Mary', 'admit', ';', 'workout', 'consisted', 'exercising', 'poor', 'judgment', '.']\n"
     ]
    }
   ],
   "source": [
    "#2} Stop Words : Common words which are often removed during nlp usage\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#nltk.download(\"stop words\")\n",
    "\n",
    "stopwords= set(stopwords.words(\"english\"))\n",
    "\n",
    "filtered_words = []\n",
    "\n",
    "for w in tokens:\n",
    "    if w not in stopwords:\n",
    "        filtered_words.append(w)\n",
    "print(\"\\nThe stop words are removed now, Tokenized words or filtered tokenized words are : \\n\\n\",filtered_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e54fb254",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:39:36.809478Z",
     "iopub.status.busy": "2024-07-04T09:39:36.808776Z",
     "iopub.status.idle": "2024-07-04T09:39:36.816445Z",
     "shell.execute_reply": "2024-07-04T09:39:36.815080Z"
    },
    "papermill": {
     "duration": 0.018167,
     "end_time": "2024-07-04T09:39:36.819756",
     "exception": false,
     "start_time": "2024-07-04T09:39:36.801589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stemmed list items are: \t ['organ', 'organiz', 'factual']\n"
     ]
    }
   ],
   "source": [
    "#3} Stemming : Reduces the words to their root form or base form\n",
    "from nltk.stem import PorterStemmer\n",
    "words = [\"Organization\",\"Organizational\",\"Factual\"]\n",
    "#    list item stemming\n",
    "stem_li = []\n",
    "ps = PorterStemmer()\n",
    "for i in words:\n",
    "    stem_li.append(ps.stem(i))\n",
    "\n",
    "print(\"The stemmed list items are: \\t\",stem_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82449918",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:39:36.837823Z",
     "iopub.status.busy": "2024-07-04T09:39:36.836976Z",
     "iopub.status.idle": "2024-07-04T09:39:36.845331Z",
     "shell.execute_reply": "2024-07-04T09:39:36.844159Z"
    },
    "papermill": {
     "duration": 0.020853,
     "end_time": "2024-07-04T09:39:36.848499",
     "exception": false,
     "start_time": "2024-07-04T09:39:36.827646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The stemmed list of tokenized words are : \t ['He', 'step', 'gingerli', 'onto', 'the', 'bridg', 'know', ',', 'that', 'enchant', 'await', 'on', 'the', 'other', 'side', '.', 'It', 'wa', 'difficult', 'for', 'mari', 'to', 'admit', ';', 'that', 'most', 'of', 'her', 'workout', 'consist', 'of', 'exercis', 'poor', 'judgment', '.']\n"
     ]
    }
   ],
   "source": [
    "#    Stemming for words on word tokens\n",
    "stem_words = []\n",
    "for i in tokens:\n",
    "    stem_words.append(ps.stem(i))\n",
    "    \n",
    "print(\"\\nThe stemmed list of tokenized words are : \\t\",stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54a32e33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:39:36.863842Z",
     "iopub.status.busy": "2024-07-04T09:39:36.863028Z",
     "iopub.status.idle": "2024-07-04T09:39:36.869702Z",
     "shell.execute_reply": "2024-07-04T09:39:36.868610Z"
    },
    "papermill": {
     "duration": 0.017417,
     "end_time": "2024-07-04T09:39:36.873034",
     "exception": false,
     "start_time": "2024-07-04T09:39:36.855617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stemmed list of tokenized sentence are : \t ['he stepped gingerly onto the bridge knowing, that enchantment awaited on the other side.', 'it was difficult for mary to admit; that most of her workout consisted of exercising poor judgment.']\n"
     ]
    }
   ],
   "source": [
    "#    Stemming for senteces on sentenced tokens \n",
    "stem_sentence = []\n",
    "for i in tokens_sent:\n",
    "    stem_sentence.append(ps.stem(i))\n",
    "    \n",
    "print(\"The stemmed list of tokenized sentence are : \\t\",stem_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40e542ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:39:36.892963Z",
     "iopub.status.busy": "2024-07-04T09:39:36.892052Z",
     "iopub.status.idle": "2024-07-04T09:39:36.979468Z",
     "shell.execute_reply": "2024-07-04T09:39:36.978215Z"
    },
    "papermill": {
     "duration": 0.100974,
     "end_time": "2024-07-04T09:39:36.982010",
     "exception": false,
     "start_time": "2024-07-04T09:39:36.881036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4} Lemmatization : Breaks the words into simpler forms and makes meaning full words unlike stemming\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87053b45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:39:36.996468Z",
     "iopub.status.busy": "2024-07-04T09:39:36.996030Z",
     "iopub.status.idle": "2024-07-04T09:39:38.519925Z",
     "shell.execute_reply": "2024-07-04T09:39:38.518611Z"
    },
    "papermill": {
     "duration": 1.534613,
     "end_time": "2024-07-04T09:39:38.523004",
     "exception": false,
     "start_time": "2024-07-04T09:39:36.988391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /usr/share/nltk_data/corpora/wordnet.zip\r\n",
      "   creating: /usr/share/nltk_data/corpora/wordnet/\r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/README  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \r\n"
     ]
    }
   ],
   "source": [
    "#Cause the source file is compressed, and you need to uncompressed it. because the notebook can't do that automaticaly for now.\n",
    "!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4846075d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:39:38.539773Z",
     "iopub.status.busy": "2024-07-04T09:39:38.539331Z",
     "iopub.status.idle": "2024-07-04T09:39:40.931638Z",
     "shell.execute_reply": "2024-07-04T09:39:40.930353Z"
    },
    "papermill": {
     "duration": 2.404299,
     "end_time": "2024-07-04T09:39:40.934463",
     "exception": false,
     "start_time": "2024-07-04T09:39:38.530164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lemmatized words of the list are : \t ['Organization', 'Organizational', 'Factual']\n"
     ]
    }
   ],
   "source": [
    "wl=WordNetLemmatizer()\n",
    "\n",
    "#   list item lemmitization\n",
    "lemma_li=[]\n",
    "for i in words: \n",
    "    lemma_li.append(wl.lemmatize(i))\n",
    "    \n",
    "print(\"The lemmatized words of the list are : \\t\",lemma_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68686ddf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:39:40.950495Z",
     "iopub.status.busy": "2024-07-04T09:39:40.950053Z",
     "iopub.status.idle": "2024-07-04T09:39:40.957508Z",
     "shell.execute_reply": "2024-07-04T09:39:40.956166Z"
    },
    "papermill": {
     "duration": 0.018543,
     "end_time": "2024-07-04T09:39:40.960104",
     "exception": false,
     "start_time": "2024-07-04T09:39:40.941561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lemmatized words of the sentence words tokens will be : \n",
      " ['He', 'stepped', 'gingerly', 'onto', 'the', 'bridge', 'knowing', ',', 'that', 'enchantment', 'awaited', 'on', 'the', 'other', 'side', '.', 'It', 'wa', 'difficult', 'for', 'Mary', 'to', 'admit', ';', 'that', 'most', 'of', 'her', 'workout', 'consisted', 'of', 'exercising', 'poor', 'judgment', '.']\n"
     ]
    }
   ],
   "source": [
    "lemma_words = []\n",
    "for i in tokens:\n",
    "    lemma_words.append(wl.lemmatize(i))\n",
    "    \n",
    "print(\"The lemmatized words of the sentence words tokens will be : \\n\",lemma_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fe9d1c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:39:40.976614Z",
     "iopub.status.busy": "2024-07-04T09:39:40.975905Z",
     "iopub.status.idle": "2024-07-04T09:39:40.982128Z",
     "shell.execute_reply": "2024-07-04T09:39:40.981054Z"
    },
    "papermill": {
     "duration": 0.018043,
     "end_time": "2024-07-04T09:39:40.985402",
     "exception": false,
     "start_time": "2024-07-04T09:39:40.967359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lemmatized sentence will be of the paragraph is : \n",
      " ['He stepped gingerly onto the bridge knowing, that enchantment awaited on the other side.', 'It was difficult for Mary to admit; that most of her workout consisted of exercising poor judgment.']\n"
     ]
    }
   ],
   "source": [
    "lemma_sentence = []\n",
    "for i in tokens_sent:\n",
    "    lemma_sentence.append(wl.lemmatize(i))\n",
    "    \n",
    "print(\"The lemmatized sentence will be of the paragraph is : \\n\",lemma_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99856dfb",
   "metadata": {
    "papermill": {
     "duration": 0.006996,
     "end_time": "2024-07-04T09:39:40.999870",
     "exception": false,
     "start_time": "2024-07-04T09:39:40.992874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.944914,
   "end_time": "2024-07-04T09:39:42.030594",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-04T09:39:30.085680",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
